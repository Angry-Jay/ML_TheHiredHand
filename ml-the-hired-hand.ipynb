{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "yZg8yXCtjE3J",
   "metadata": {
    "id": "yZg8yXCtjE3J"
   },
   "source": [
    "# The Hired Hand"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "h_wT-bE8f0JQ",
   "metadata": {
    "id": "h_wT-bE8f0JQ"
   },
   "source": [
    "**Machine Learning for Job Placement Prediction**\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Angry-Jay/ML_TheHiredHand/blob/main/ml-the-hired-hand.ipynb)\n",
    "\n",
    "---\n",
    "\n",
    "## Table of Contents\n",
    "\n",
    "1. [Project & Dataset Description](#1-project--dataset-description)\n",
    "   - [1.1 Project Aim](#11-project-aim)\n",
    "   - [1.2 Existing Solutions](#12-existing-solutions)\n",
    "   - [1.3 Dataset Information](#13-dataset-information)\n",
    "2. [Library Imports](#2-library-imports)\n",
    "3. [Data Access](#3-data-access)\n",
    "4. [Dataset Exploratory Analysis](#4-dataset-exploratory-analysis)\n",
    "   - [4.1 Metadata Analysis](#41-metadata-analysis)\n",
    "   - [4.2 Missing Values Analysis](#42-missing-values-analysis)\n",
    "   - [4.3 Feature Distributions, Scaling & Outliers](#43-feature-distributions-scaling--outliers)\n",
    "   - [4.4 Target Feature Study](#44-target-feature-study)\n",
    "   - [4.5 Feature Correlation & Selection](#45-feature-correlation--selection)\n",
    "   - [4.6 Unsupervised Clustering](#46-unsupervised-clustering)\n",
    "   - [4.7 Interpretations & Conclusions](#47-interpretations--conclusions)\n",
    "5. [ML Baseline & Ensemble Models](#5-ml-baseline--ensemble-models)\n",
    "   - [5.1 Train/Validation/Test Splits](#51-trainvalidationtest-splits)\n",
    "   - [5.2 Pipelines & Models](#52-pipelines--models)\n",
    "   - [5.3 Training & Validation](#53-training--validation)\n",
    "   - [5.4 Testing](#54-testing)\n",
    "   - [5.5 Results Interpretation & Discussion](#55-results-interpretation--discussion)\n",
    "6. [Enhanced Models & Hyperparameter Tuning](#6-enhanced-models--hyperparameter-tuning)\n",
    "   - [6.1 Justification of Choices](#61-justification-of-choices)\n",
    "   - [6.2 Hyperparameter Optimization](#62-hyperparameter-optimization)\n",
    "   - [6.3 Final Results & Analysis](#63-final-results--analysis)\n",
    "7. [Conclusion & Future Work](#7-conclusion--future-work)\n",
    "\n",
    "---\n",
    "\n",
    "## 1. Project & Dataset Description\n",
    "\n",
    "### 1.1 Project Aim\n",
    "\n",
    "This project applies Machine Learning techniques to predict employment outcomes for graduating students using the **Job Placement Dataset**. \n",
    "\n",
    "**Primary Objectives:**\n",
    "- **Predict employment outcomes** (Placed vs. Not Placed) based on demographic, academic, and professional attributes\n",
    "- **Demonstrate a coherent ML methodology** from data discovery through model optimization\n",
    "- **Apply comprehensive data analysis** including:\n",
    "  - Data cleaning and preprocessing\n",
    "  - Exploratory Data Analysis (EDA)\n",
    "  - Feature engineering and selection\n",
    "  - Correlation and clustering analysis\n",
    "- **Build and evaluate multiple classification models** with proper validation techniques\n",
    "- **Identify key employability factors** through feature importance analysis and model interpretation\n",
    "- **Apply ML best practices** including proper train/validation/test splits, pipeline construction, and hyperparameter tuning\n",
    "\n",
    "---\n",
    "\n",
    "### 1.2 Existing Solutions\n",
    "\n",
    "**Traditional Approach:**\n",
    "\n",
    "Historically, HR departments and educational institutions rely on manual screening processes with heuristic filters (e.g., GPA cutoffs, specific degree specializations, work experience thresholds). This traditional approach has several limitations:\n",
    "- Time-consuming and difficult to scale\n",
    "- Subjective and prone to human bias\n",
    "- Often inaccurate in predicting actual job placement success\n",
    "- Fails to capture complex interactions between multiple factors\n",
    "\n",
    "**Machine Learning Solutions:**\n",
    "\n",
    "Several ML-based approaches exist on platforms like Kaggle and GitHub for placement prediction:\n",
    "\n",
    "**Common Algorithms Used:**\n",
    "- **Baseline Models:** Logistic Regression, K-Nearest Neighbors (KNN)\n",
    "- **Tree-based Models:** Decision Trees, Random Forest, ExtraTrees\n",
    "- **Boosting Methods:** XGBoost, AdaBoost, Gradient Boosting\n",
    "- **Support Vector Machines:** SVC with various kernels\n",
    "\n",
    "**Key Findings from Literature:**\n",
    "- Tree-based ensemble methods (Random Forest, XGBoost) typically outperform simpler baselines\n",
    "- Non-linear models better capture feature interactions (e.g., combined effect of GPA and work experience)\n",
    "- Feature engineering significantly impacts model performance\n",
    "- Proper handling of class imbalance is crucial for accurate predictions\n",
    "\n",
    "**Typical Methodology:**\n",
    "1. Exploratory Data Analysis (distributions, correlations, class imbalance)\n",
    "2. Preprocessing pipelines (encoding categorical variables, scaling, imputation)\n",
    "3. Model comparison using multiple metrics: Accuracy, Precision, Recall, F1-Score, ROC-AUC\n",
    "4. Hyperparameter tuning using GridSearchCV or RandomizedSearchCV\n",
    "5. Feature importance analysis for interpretability\n",
    "\n",
    "---\n",
    "\n",
    "### 1.3 Dataset Information\n",
    "\n",
    "**Dataset Name:** Job Placement Dataset\n",
    "\n",
    "**Original Source:** [Kaggle - Job Placement Dataset](https://www.kaggle.com/datasets/ahsan81/job-placement-dataset/data)\n",
    "\n",
    "**Dataset Characteristics:**\n",
    "- **Type:** Dense, structured tabular data\n",
    "- **Size:** Small-to-medium (215 instances, 15 features)\n",
    "- **Features:** Mix of numeric and categorical variables\n",
    "- **Target Variable:** Binary classification (Placed / Not Placed)\n",
    "- **Quality:** Mostly clean with minimal missing values\n",
    "\n",
    "**Dataset Access:**\n",
    "- **GitHub Repository:** `https://github.com/Angry-Jay/ML_TheHiredHand`\n",
    "- **Raw Data URL:** `https://raw.githubusercontent.com/Angry-Jay/ML_TheHiredHand/main/Job_Placement_Data.csv`\n",
    "\n",
    "**Features Overview:**\n",
    "- Student demographics (gender)\n",
    "- Academic performance (SSC %, HSC %, Degree %, MBA %)\n",
    "- Educational background (SSC board, HSC board, HSC specialization, Degree type, MBA specialization)\n",
    "- Work experience\n",
    "- Employment test scores\n",
    "- Salary (target-dependent, removed to prevent data leakage)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nLt-pHGeqVQk",
   "metadata": {
    "id": "nLt-pHGeqVQk"
   },
   "source": [
    "## 2. Library Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "yuLL6t7xfjF9",
   "metadata": {
    "id": "yuLL6t7xfjF9"
   },
   "outputs": [],
   "source": [
    "# Setting up\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Preprocessing & Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "\n",
    "# Model Selection & Tuning\n",
    "from sklearn.model_selection import (\n",
    "    GridSearchCV,\n",
    "    RandomizedSearchCV,\n",
    "    cross_val_score,\n",
    "    train_test_split,\n",
    ")\n",
    "\n",
    "# Models\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Metrics\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    f1_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    roc_auc_score,\n",
    ")\n",
    "\n",
    "# Configuration\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "L4DKOMIjqkxl",
   "metadata": {
    "id": "L4DKOMIjqkxl"
   },
   "source": [
    "## 3. Data Access"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wYM1JqfJlgRO",
   "metadata": {
    "id": "wYM1JqfJlgRO"
   },
   "outputs": [],
   "source": [
    "DATA_URL = \"https://raw.githubusercontent.com/Angry-Jay/ML_TheHiredHand/refs/heads/main/Job_Placement_Data.csv\"\n",
    "\n",
    "try:\n",
    "  # Load the dataset directly into a Pandas DataFrame\n",
    "  df = pd.read_csv(DATA_URL)\n",
    "\n",
    "  print(\" Dataset loaded successfully!\")\n",
    "  print(f\"Shape: {df.shape[0]} rows, {df.shape[1]} columns\")\n",
    "\n",
    "  # Display the first 5 rows to verify\n",
    "  display(df.head())\n",
    "\n",
    "except Exception as e:\n",
    "  print(\"Error loading data. Check your URL.\")\n",
    "  print(f\"Error details: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dlhLvQwVqrEU",
   "metadata": {
    "id": "dlhLvQwVqrEU"
   },
   "source": [
    "## 4. Dataset Exploratory Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rP1msGkOoMm8",
   "metadata": {
    "collapsed": true,
    "id": "rP1msGkOoMm8"
   },
   "source": [
    "### 4.1 Metadata Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9917HzRuxAi",
   "metadata": {
    "id": "e9917HzRuxAi"
   },
   "outputs": [],
   "source": [
    "# Display dataset info\n",
    "df.info()\n",
    "\n",
    "# Dropping irrelevant or leakage columns\n",
    "# 'sl_no' is just an ID. 'salary' causes data leakage for classification as only placed students have it\n",
    "columns_to_drop = ['sl_no', 'salary']\n",
    "df_clean = df.drop(columns=[c for c in columns_to_drop if c in df.columns], errors='ignore')\n",
    "\n",
    "# Checking for duplicates\n",
    "duplicates = df_clean.duplicated().sum()\n",
    "print(f\"\\nNumber of duplicates found: {duplicates}\")\n",
    "if duplicates > 0:\n",
    "  df_clean = df_clean.drop_duplicates()\n",
    "  print(\"Duplicates removed\")\n",
    "\n",
    "# Display basic statistics\n",
    "print(\"\\n--- Dataset Shape ---\")\n",
    "print(f\"Rows: {df_clean.shape[0]}, Columns: {df_clean.shape[1]}\")\n",
    "\n",
    "print(\"\\n--- Feature Types ---\")\n",
    "print(df_clean.dtypes)\n",
    "\n",
    "# Display statistical summary for numerical features\n",
    "print(\"\\n--- Numerical Feature Statistics ---\")\n",
    "display(df_clean.describe())\n",
    "\n",
    "# Display sample rows\n",
    "print(\"\\n--- Sample Data ---\")\n",
    "display(df_clean.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6wkcli5oth",
   "metadata": {},
   "source": [
    "### 4.2 Missing Values Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ns9tniisnzm",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"--- Missing Values per Feature ---\")\n",
    "print(df_clean.isnull().sum())\n",
    "\n",
    "print(\"\\n--- Missing Values Percentage ---\")\n",
    "print((df_clean.isnull().sum() / len(df_clean) * 100).round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "z5ds0jss7j",
   "metadata": {},
   "source": [
    "### 4.3 Feature Distributions, Scaling & Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cl39rkn1jwj",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fpec963ybwf",
   "metadata": {},
   "source": [
    "### 4.4 Target Feature Study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "zpteycwzv7o",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ido0ujpu1m",
   "metadata": {},
   "source": [
    "### 4.5 Feature Correlation & Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cq5lfcgssn",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "n1uutp5z6qr",
   "metadata": {},
   "source": [
    "### 4.6 Unsupervised Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8emgkzabdb4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b1xqgtjif38",
   "metadata": {},
   "source": [
    "### 4.7 Interpretations & Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vqc8z5vqw4l",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 5. ML Baseline & Ensemble Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gt7bbs25u3k",
   "metadata": {},
   "source": [
    "### 5.1 Train/Validation/Test Splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1y89f4ne4ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "w0em90lymgs",
   "metadata": {},
   "source": [
    "### 5.2 Pipelines & Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "n3uayft3v9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7p38rbqmjzj",
   "metadata": {},
   "source": [
    "### 5.3 Training & Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8y4eycfir0j",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "rcsmc5lyfa",
   "metadata": {},
   "source": [
    "### 5.4 Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "l7y521g4zp",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "t4wn484c6q",
   "metadata": {},
   "source": [
    "### 5.5 Results Interpretation & Discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cvggwxipyvh",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 6. Enhanced Models & Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "kg16rtxrd5",
   "metadata": {},
   "source": [
    "### 6.1 Justification of Choices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8m27bj9o9qf",
   "metadata": {},
   "source": [
    "### 6.2 Hyperparameter Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tl2fadk15o",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "qxdtuqjiu4b",
   "metadata": {},
   "source": [
    "### 6.3 Final Results & Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9kggnmk5w1v",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ur24e8fjq9",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 7. Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18f01f20",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
