{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# The Hired Hand"
      ],
      "metadata": {
        "id": "yZg8yXCtjE3J"
      },
      "id": "yZg8yXCtjE3J"
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Machine Learning for Job Placement Prediction**\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Angry-Jay/ML_TheHiredHand/blob/main/ml-the-hired-hand.ipynb)\n",
        "\n",
        "---\n",
        "\n",
        "## Table of Contents\n",
        "\n",
        "- [Project Overview](#project-overview)\n",
        "- [Dataset Information](#dataset-information)\n",
        "- [Project Objectives](#project-objectives)\n",
        "- [Methodology](#methodology)\n",
        "\n",
        "---\n",
        "\n",
        "## Project Overview\n",
        "\n",
        "This project applies Machine Learning techniques to predict employment outcomes for graduating students using the **Job Placement Dataset** from Kaggle. The goal is to build a robust binary classification model that predicts whether a student will be placed (employed) or not placed based on their demographic, academic, and professional attributes.\n",
        "\n",
        "---\n",
        "\n",
        "## Dataset Information\n",
        "\n",
        "**Dataset Name:** Job Placement Dataset\n",
        "**Source:** [Kaggle - Job Placement Dataset](https://www.kaggle.com/datasets/ahsan81/job-placement-dataset/data)\n",
        "**Size:** Small/medium-sized tabular dataset\n",
        "**Type:** Binary classification problem\n",
        "\n",
        "**Features Include:**\n",
        "- **Academic Performance:** Secondary education percentage, higher secondary percentage, degree percentage\n",
        "- **Educational Background:** Board of education, degree specialization, field of study\n",
        "- **Professional Attributes:** Work experience, employability test scores\n",
        "- **Target Variable:** Placement status (Placed / Not Placed)\n",
        "\n",
        "**Dataset Characteristics:**\n",
        "- Heterogeneous data (numerical and categorical features)\n",
        "- Potential class imbalance\n",
        "- Real-world data with possible missing values\n",
        "\n",
        "---\n",
        "\n",
        "## Project Objectives\n",
        "\n",
        "1. **Predict employment outcomes** (Placed vs. Not Placed) with high accuracy and reliability\n",
        "2. **Conduct comprehensive data analysis** including:\n",
        "   - Data cleaning and preprocessing\n",
        "   - Exploratory Data Analysis (EDA)\n",
        "   - Feature engineering and selection\n",
        "   - Correlation analysis\n",
        "3. **Build and evaluate multiple classification models** with proper validation\n",
        "4. **Identify key employability factors** through feature importance analysis\n",
        "5. **Apply ML best practices** throughout the pipeline"
      ],
      "metadata": {
        "id": "h_wT-bE8f0JQ"
      },
      "id": "h_wT-bE8f0JQ"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Setting up imports and environment"
      ],
      "metadata": {
        "id": "nLt-pHGeqVQk"
      },
      "id": "nLt-pHGeqVQk"
    },
    {
      "cell_type": "code",
      "source": [
        "# Setting up\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Preprocessing & Pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "\n",
        "# Model Selection & Tuning\n",
        "from sklearn.model_selection import (\n",
        "    GridSearchCV,\n",
        "    RandomizedSearchCV,\n",
        "    cross_val_score,\n",
        "    train_test_split,\n",
        ")\n",
        "\n",
        "# Models\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# Metrics\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score,\n",
        "    classification_report,\n",
        "    confusion_matrix,\n",
        "    f1_score,\n",
        "    precision_score,\n",
        "    recall_score,\n",
        "    roc_auc_score,\n",
        ")\n",
        "\n",
        "# Configuration\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "yuLL6t7xfjF9"
      },
      "id": "yuLL6t7xfjF9",
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Data Access"
      ],
      "metadata": {
        "id": "L4DKOMIjqkxl"
      },
      "id": "L4DKOMIjqkxl"
    },
    {
      "cell_type": "code",
      "source": [
        "DATA_URL = \"https://raw.githubusercontent.com/Angry-Jay/ML_TheHiredHand/refs/heads/main/Job_Placement_Data.csv\"\n",
        "\n",
        "try:\n",
        "  # Load the dataset directly into a Pandas DataFrame\n",
        "  df = pd.read_csv(DATA_URL)\n",
        "\n",
        "  print(\" Dataset loaded successfully!\")\n",
        "  print(f\"Shape: {df.shape[0]} rows, {df.shape[1]} columns\")\n",
        "\n",
        "  # Display the first 5 rows to verify\n",
        "  display(df.head())\n",
        "\n",
        "except Exception as e:\n",
        "  print(\"Error loading data. Check your URL.\")\n",
        "  print(f\"Error details: {e}\")"
      ],
      "metadata": {
        "id": "wYM1JqfJlgRO"
      },
      "id": "wYM1JqfJlgRO",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Initial data inspection & cleaning"
      ],
      "metadata": {
        "id": "dlhLvQwVqrEU"
      },
      "id": "dlhLvQwVqrEU"
    },
    {
      "cell_type": "code",
      "source": [
        "from os import dup\n",
        "df.info()\n",
        "\n",
        "# Dropping irrelevant or leakage columns\n",
        "# 'sl_no' is just an ID. 'salary' causes data leakage for classification as only placed students have it\n",
        "columns_to_drop = ['sl_no', 'salary']\n",
        "df_clean = df.drop(columns = [ c for c in columns_to_drop if c in df.columns], errors='ignore')\n",
        "\n",
        "# Checking for duplicates\n",
        "duplicates = df_clean.duplicated().sum()\n",
        "print(f\"Number of duplicates found: {duplicates}\")\n",
        "if duplicates > 0:\n",
        "  df_clean = df_clean.drop_duplicates(inplace= True)\n",
        "  print(\"Duplicates removed\")\n",
        "\n",
        "# Check for Missing Values\n",
        "print(\"\\n--- Missing Values per Feature ---\")\n",
        "print(df_clean.isnull().sum())\n",
        "\n",
        "# Display statistical summary for numerical features\n",
        "print(\"\\n--- Numerical Feature Statistics ---\")\n",
        "display(df_clean.describe())\n",
        "\n",
        "# Display sample rows\n",
        "print(\"\\n--- Sample Data ---\")\n",
        "display(df_clean.head())"
      ],
      "metadata": {
        "collapsed": true,
        "id": "rP1msGkOoMm8"
      },
      "id": "rP1msGkOoMm8",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "e9917HzRuxAi"
      },
      "id": "e9917HzRuxAi",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}