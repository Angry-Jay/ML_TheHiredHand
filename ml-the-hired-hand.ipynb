{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "yZg8yXCtjE3J",
   "metadata": {
    "id": "yZg8yXCtjE3J"
   },
   "source": [
    "# The Hired Hand"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "h_wT-bE8f0JQ",
   "metadata": {
    "id": "h_wT-bE8f0JQ"
   },
   "source": [
    "**Machine Learning for Job Change Prediction**\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Angry-Jay/ML_TheHiredHand/blob/main/ml-the-hired-hand.ipynb)\n",
    "\n",
    "---\n",
    "\n",
    "## Table of Contents\n",
    "\n",
    "1. [Project & Dataset Description](#1-project--dataset-description)\n",
    "   - [1.1 Project Aim](#11-project-aim)\n",
    "   - [1.2 Existing Solutions](#12-existing-solutions)\n",
    "   - [1.3 Dataset Information](#13-dataset-information)\n",
    "2. [Library Imports](#2-library-imports)\n",
    "3. [Data Access](#3-data-access)\n",
    "4. [Dataset Exploratory Analysis](#4-dataset-exploratory-analysis)\n",
    "   - [4.1 Metadata Analysis](#41-metadata-analysis)\n",
    "   - [4.2 Missing Values Analysis](#42-missing-values-analysis)\n",
    "   - [4.3 Feature Distributions, Scaling & Outliers](#43-feature-distributions-scaling--outliers)\n",
    "   - [4.4 Target Feature Study](#44-target-feature-study)\n",
    "   - [4.5 Feature Correlation & Selection](#45-feature-correlation--selection)\n",
    "   - [4.6 Unsupervised Clustering](#46-unsupervised-clustering)\n",
    "   - [4.7 Interpretations & Conclusions](#47-interpretations--conclusions)\n",
    "5. [ML Baseline & Ensemble Models](#5-ml-baseline--ensemble-models)\n",
    "   - [5.1 Train/Validation/Test Splits](#51-trainvalidationtest-splits)\n",
    "   - [5.2 Pipelines & Models](#52-pipelines--models)\n",
    "   - [5.3 Training & Validation](#53-training--validation)\n",
    "   - [5.4 Testing](#54-testing)\n",
    "   - [5.5 Results Interpretation & Discussion](#55-results-interpretation--discussion)\n",
    "6. [Enhanced Models & Hyperparameter Tuning](#6-enhanced-models--hyperparameter-tuning)\n",
    "   - [6.1 Justification of Choices](#61-justification-of-choices)\n",
    "   - [6.2 Hyperparameter Optimization](#62-hyperparameter-optimization)\n",
    "   - [6.3 Final Results & Analysis](#63-final-results--analysis)\n",
    "7. [Conclusion & Future Work](#7-conclusion--future-work)\n",
    "\n",
    "---\n",
    "\n",
    "## 1. Project & Dataset Description\n",
    "\n",
    "### 1.1 Project Aim\n",
    "\n",
    "This project applies Machine Learning techniques to predict job-change behavior for data science candidates using the **HR Analytics: Job Change of Data Scientists** dataset from Kaggle.\n",
    "\n",
    "**Primary Objectives:**\n",
    "- **Predict job-change probability** (target = 1: looking for job change; target = 0: not looking) based on demographic, educational, and professional attributes\n",
    "- **Demonstrate a coherent ML methodology** from data discovery through model optimization\n",
    "- **Apply comprehensive data analysis** including:\n",
    "  - Data cleaning and preprocessing\n",
    "  - Exploratory Data Analysis (EDA)\n",
    "  - Feature engineering and selection\n",
    "  - Correlation and clustering analysis\n",
    "- **Build and evaluate multiple classification models** with proper validation techniques\n",
    "- **Identify key factors** influencing job-change decisions through feature importance analysis\n",
    "- **Apply ML best practices** including proper train/validation/test splits, pipeline construction, and hyperparameter tuning\n",
    "\n",
    "---\n",
    "\n",
    "### 1.2 Existing Solutions\n",
    "\n",
    "**Traditional Approach:**\n",
    "\n",
    "HR departments traditionally rely on manual candidate assessment with heuristic filters (e.g., years of experience, specific education levels, company type). This approach has several limitations:\n",
    "- Time-consuming and difficult to scale\n",
    "- Subjective and prone to human bias\n",
    "- Often inaccurate in predicting actual behavior\n",
    "- Fails to capture complex interactions between multiple factors\n",
    "\n",
    "**Machine Learning Solutions:**\n",
    "\n",
    "Several ML-based approaches exist for HR analytics and employee retention prediction:\n",
    "\n",
    "**Common Algorithms Used:**\n",
    "- **Baseline Models:** Logistic Regression, K-Nearest Neighbors (KNN)\n",
    "- **Tree-based Models:** Decision Trees, Random Forest, ExtraTrees\n",
    "- **Boosting Methods:** XGBoost, LightGBM, CatBoost, AdaBoost\n",
    "- **Support Vector Machines:** SVC with various kernels\n",
    "\n",
    "**Key Findings from Literature:**\n",
    "- Tree-based ensemble methods (Random Forest, XGBoost, LightGBM) typically outperform simpler baselines\n",
    "- Gradient boosting models (LightGBM, CatBoost) handle categorical features natively and efficiently\n",
    "- Feature engineering significantly impacts model performance\n",
    "- Proper handling of class imbalance is crucial for accurate predictions\n",
    "- Training hours and relevant experience are often among the strongest predictors\n",
    "\n",
    "**Typical Methodology:**\n",
    "1. Exploratory Data Analysis (distributions, correlations, class imbalance)\n",
    "2. Preprocessing pipelines (encoding categorical variables, imputation, scaling)\n",
    "3. Model comparison using multiple metrics: Accuracy, Precision, Recall, F1-Score, ROC-AUC\n",
    "4. Hyperparameter tuning using GridSearchCV or RandomizedSearchCV\n",
    "5. Feature importance analysis for interpretability\n",
    "\n",
    "---\n",
    "\n",
    "### 1.3 Dataset Information\n",
    "\n",
    "**Dataset Name:** HR Analytics: Job Change of Data Scientists\n",
    "\n",
    "**Original Source:** [Kaggle - HR Analytics (arashnic)](https://www.kaggle.com/datasets/arashnic/hr-analytics-job-change-of-data-scientists)\n",
    "\n",
    "**Dataset Characteristics:**\n",
    "- **Type:** Dense, structured tabular data\n",
    "- **Size:** Medium (19,158 training instances, 13 features + target)\n",
    "- **Features:** Mix of numeric and categorical variables (mostly categorical)\n",
    "- **Target Variable:** Binary classification (0 = not looking for job change, 1 = looking for job change)\n",
    "- **Quality:** Real-world data with missing values and class imbalance\n",
    "- **License:** CC0 (Public Domain)\n",
    "\n",
    "**Dataset Context:**\n",
    "\n",
    "A company active in Big Data and Data Science conducts training programs and wants to identify which candidates are likely to work for the company after training versus those looking for new employment. This helps reduce cost and time while improving training quality and candidate planning.\n",
    "\n",
    "**Dataset Files:**\n",
    "- `aug_train.csv` - Training data with target labels\n",
    "- `aug_test.csv` - Test data without target labels  \n",
    "- `sample_submission.csv` - Submission format example\n",
    "\n",
    "**Key Features:**\n",
    "- `enrollee_id`: Unique ID for candidate\n",
    "- `city`: City code\n",
    "- `city_development_index`: Development index of the city (scaled)\n",
    "- `gender`: Gender of candidate\n",
    "- `relevent_experience`: Relevant experience (Has relevant experience / No relevant experience)\n",
    "- `enrolled_university`: Type of university course enrolled if any\n",
    "- `education_level`: Education level of candidate\n",
    "- `major_discipline`: Education major discipline\n",
    "- `experience`: Candidate total experience in years\n",
    "- `company_size`: Number of employees in current employer's company\n",
    "- `company_type`: Type of current employer\n",
    "- `last_new_job`: Difference in years between previous job and current job\n",
    "- `training_hours`: Training hours completed\n",
    "- `target`: 0 - Not looking for job change, 1 - Looking for job change\n",
    "\n",
    "**Dataset Access:**\n",
    "- **Kaggle:** `https://www.kaggle.com/datasets/arashnic/hr-analytics-job-change-of-data-scientists`\n",
    "- **GitHub Repository:** `https://github.com/Angry-Jay/ML_TheHiredHand`\n",
    "- For this notebook, we'll load from local file: `aug_train.csv`\n",
    "\n",
    "**Known Challenges:**\n",
    "- Dataset is imbalanced (more candidates not looking for job change)\n",
    "- Most features are categorical with high cardinality\n",
    "- Missing values present in several features requiring imputation strategy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nLt-pHGeqVQk",
   "metadata": {
    "id": "nLt-pHGeqVQk"
   },
   "source": [
    "## 2. Library Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "yuLL6t7xfjF9",
   "metadata": {
    "id": "yuLL6t7xfjF9"
   },
   "outputs": [],
   "source": [
    "# Setting up\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Preprocessing & Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "\n",
    "# Model Selection & Tuning\n",
    "from sklearn.model_selection import (\n",
    "    GridSearchCV,\n",
    "    RandomizedSearchCV,\n",
    "    cross_val_score,\n",
    "    train_test_split,\n",
    ")\n",
    "\n",
    "# Models\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Metrics\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    f1_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    roc_auc_score,\n",
    ")\n",
    "\n",
    "# Configuration\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "L4DKOMIjqkxl",
   "metadata": {
    "id": "L4DKOMIjqkxl"
   },
   "source": [
    "## 3. Data Access"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wYM1JqfJlgRO",
   "metadata": {
    "id": "wYM1JqfJlgRO"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dlhLvQwVqrEU",
   "metadata": {
    "id": "dlhLvQwVqrEU"
   },
   "source": [
    "## 4. Dataset Exploratory Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rP1msGkOoMm8",
   "metadata": {
    "collapsed": true,
    "id": "rP1msGkOoMm8"
   },
   "source": [
    "### 4.1 Metadata Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "j9zobh3uwem",
   "metadata": {},
   "source": [
    "In this section, we analyze the dataset's metadata to understand its structure, data types, quality, and characteristics. This initial exploration helps identify:\n",
    "\n",
    "- **Dataset dimensions** and scale\n",
    "- **Feature data types** (numerical vs. categorical)\n",
    "- **Data quality issues** (duplicates, missing values, irrelevant columns)\n",
    "- **Statistical properties** of numerical features\n",
    "- **Potential data leakage** concerns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9917HzRuxAi",
   "metadata": {
    "id": "e9917HzRuxAi"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f6wkcli5oth",
   "metadata": {},
   "source": [
    "### 4.2 Missing Values Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ns9tniisnzm",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "z5ds0jss7j",
   "metadata": {},
   "source": [
    "### 4.3 Feature Distributions, Scaling & Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "kxjsohtf7di",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fpec963ybwf",
   "metadata": {},
   "source": [
    "### 4.4 Target Feature Study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "zpteycwzv7o",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ido0ujpu1m",
   "metadata": {},
   "source": [
    "### 4.5 Feature Correlation & Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cq5lfcgssn",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "n1uutp5z6qr",
   "metadata": {},
   "source": [
    "### 4.6 Unsupervised Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8emgkzabdb4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b1xqgtjif38",
   "metadata": {},
   "source": [
    "### 4.7 Interpretations & Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vqc8z5vqw4l",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 5. ML Baseline & Ensemble Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gt7bbs25u3k",
   "metadata": {},
   "source": [
    "### 5.1 Train/Validation/Test Splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1y89f4ne4ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "w0em90lymgs",
   "metadata": {},
   "source": [
    "### 5.2 Pipelines & Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "n3uayft3v9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7p38rbqmjzj",
   "metadata": {},
   "source": [
    "### 5.3 Training & Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8y4eycfir0j",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "rcsmc5lyfa",
   "metadata": {},
   "source": [
    "### 5.4 Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "l7y521g4zp",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "t4wn484c6q",
   "metadata": {},
   "source": [
    "### 5.5 Results Interpretation & Discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cvggwxipyvh",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 6. Enhanced Models & Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "kg16rtxrd5",
   "metadata": {},
   "source": [
    "### 6.1 Justification of Choices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8m27bj9o9qf",
   "metadata": {},
   "source": [
    "### 6.2 Hyperparameter Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tl2fadk15o",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "qxdtuqjiu4b",
   "metadata": {},
   "source": [
    "### 6.3 Final Results & Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9kggnmk5w1v",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ur24e8fjq9",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 7. Conclusion"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
